#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¿ç§»å·¥å…·æµ‹è¯•è„šæœ¬ (T1.3.4)
åŠŸèƒ½ï¼šæµ‹è¯•è¿ç§»å·¥å…·ï¼ŒéªŒè¯åŠŸèƒ½æ­£ç¡®æ€§
ä½œè€…ï¼šDDDé‡æ„å·¥å…·
ç‰ˆæœ¬ï¼š1.0
åˆ›å»ºæ—¶é—´ï¼š2025-09-16
"""

import sys
import os
import subprocess
import shutil
from pathlib import Path
from typing import Dict, List, Tuple, Any
import logging
import json
import time
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('tool-test.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

class MigrationToolTester:
    """è¿ç§»å·¥å…·æµ‹è¯•ç±»"""
    
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.tools_dir = self.project_root / "migration-tools"
        self.test_report = {
            "timestamp": datetime.now().isoformat(),
            "test_results": {},
            "overall_status": "UNKNOWN",
            "execution_time": 0,
            "tools_tested": []
        }
        
        # å·¥å…·åˆ—è¡¨
        self.tools = {
            "package_migration": {
                "script": "package-migration-script.py",
                "description": "åŒ…è¿ç§»è„šæœ¬",
                "expected_outputs": ["migration.log", "migration-report.json"]
            },
            "import_update": {
                "script": "import-update-tool.py", 
                "description": "Importæ›´æ–°å·¥å…·",
                "expected_outputs": ["import-update.log", "import-update-report.json"]
            },
            "dependency_checker": {
                "script": "dependency-checker.py",
                "description": "ä¾èµ–æ£€æŸ¥å·¥å…·", 
                "expected_outputs": ["dependency-check.log", "dependency-check-report.json"]
            }
        }
    
    def setup_test_environment(self) -> bool:
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        try:
            # åˆ›å»ºæµ‹è¯•ç›®å½•
            test_dir = self.project_root / "test-workspace"
            if test_dir.exists():
                shutil.rmtree(test_dir)
            test_dir.mkdir(parents=True, exist_ok=True)
            
            # æ¸…ç†ä¹‹å‰çš„è¾“å‡ºæ–‡ä»¶
            output_files = [
                "migration.log", "migration-report.json",
                "import-update.log", "import-update-report.json", 
                "dependency-check.log", "dependency-check-report.json",
                "tool-test.log"
            ]
            
            for output_file in output_files:
                file_path = self.project_root / output_file
                if file_path.exists():
                    try:
                        file_path.unlink()
                    except:
                        pass  # æ–‡ä»¶å¯èƒ½è¢«å ç”¨ï¼Œå¿½ç•¥
                        
            logging.info("æµ‹è¯•ç¯å¢ƒè®¾ç½®å®Œæˆ")
            return True
            
        except Exception as e:
            logging.error(f"è®¾ç½®æµ‹è¯•ç¯å¢ƒå¤±è´¥: {e}")
            return False
    
    def test_tool_exists(self, tool_name: str) -> bool:
        """æµ‹è¯•å·¥å…·æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        tool_info = self.tools[tool_name]
        script_path = self.tools_dir / tool_info["script"]
        
        if not script_path.exists():
            logging.error(f"å·¥å…·è„šæœ¬ä¸å­˜åœ¨: {script_path}")
            return False
            
        if not script_path.is_file():
            logging.error(f"å·¥å…·è·¯å¾„ä¸æ˜¯æ–‡ä»¶: {script_path}")
            return False
            
        logging.info(f"å·¥å…·æ–‡ä»¶å­˜åœ¨: {script_path}")
        return True
    
    def test_tool_syntax(self, tool_name: str) -> bool:
        """æµ‹è¯•å·¥å…·è„šæœ¬è¯­æ³•"""
        tool_info = self.tools[tool_name]
        script_path = self.tools_dir / tool_info["script"]
        
        try:
            # ä½¿ç”¨python -m py_compileæ£€æŸ¥è¯­æ³•
            result = subprocess.run([
                sys.executable, "-m", "py_compile", str(script_path)
            ], capture_output=True, text=True, timeout=30)
            
            if result.returncode == 0:
                logging.info(f"å·¥å…·è¯­æ³•æ£€æŸ¥é€šè¿‡: {tool_name}")
                return True
            else:
                logging.error(f"å·¥å…·è¯­æ³•æ£€æŸ¥å¤±è´¥ {tool_name}: {result.stderr}")
                return False
                
        except Exception as e:
            logging.error(f"å·¥å…·è¯­æ³•æ£€æŸ¥å¼‚å¸¸ {tool_name}: {e}")
            return False
    
    def test_tool_execution(self, tool_name: str, dry_run: bool = True) -> Tuple[bool, Dict]:
        """æµ‹è¯•å·¥å…·æ‰§è¡Œ"""
        tool_info = self.tools[tool_name]
        script_path = self.tools_dir / tool_info["script"]
        
        execution_result = {
            "success": False,
            "execution_time": 0,
            "return_code": -1,
            "stdout": "",
            "stderr": "",
            "output_files_created": []
        }
        
        try:
            start_time = time.time()
            
            # åˆ‡æ¢åˆ°é¡¹ç›®ç›®å½•æ‰§è¡Œ
            original_cwd = os.getcwd()
            os.chdir(self.project_root)
            
            try:
                # æ ¹æ®å·¥å…·ç±»å‹é€‰æ‹©æ‰§è¡Œæ–¹å¼
                if dry_run:
                    # å¹²è·‘æ¨¡å¼ï¼šåªæµ‹è¯•å·¥å…·èƒ½å¦å¯åŠ¨
                    result = subprocess.run([
                        sys.executable, str(script_path), "--help"
                    ], capture_output=True, text=True, timeout=60)
                else:
                    # å®é™…è¿è¡Œæ¨¡å¼
                    result = subprocess.run([
                        sys.executable, str(script_path)
                    ], capture_output=True, text=True, timeout=300)  # 5åˆ†é’Ÿè¶…æ—¶
                    
                execution_result["return_code"] = result.returncode
                execution_result["stdout"] = result.stdout
                execution_result["stderr"] = result.stderr
                
                # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
                if not dry_run:
                    for expected_file in tool_info["expected_outputs"]:
                        file_path = self.project_root / expected_file
                        if file_path.exists():
                            execution_result["output_files_created"].append(expected_file)
                
                # åˆ¤æ–­æ‰§è¡Œæ˜¯å¦æˆåŠŸ
                if dry_run:
                    # å¹²è·‘æ¨¡å¼ï¼šè¿”å›ç ä¸é‡è¦ï¼Œä¸»è¦çœ‹æ˜¯å¦èƒ½å¯åŠ¨
                    execution_result["success"] = True
                else:
                    # å®é™…è¿è¡Œï¼šè¿”å›ç 0è¡¨ç¤ºæˆåŠŸ
                    execution_result["success"] = (result.returncode == 0)
                    
            finally:
                os.chdir(original_cwd)
                
            execution_result["execution_time"] = time.time() - start_time
            
            if execution_result["success"]:
                logging.info(f"å·¥å…·æ‰§è¡Œæµ‹è¯•é€šè¿‡: {tool_name} (è€—æ—¶: {execution_result['execution_time']:.2f}s)")
            else:
                logging.error(f"å·¥å…·æ‰§è¡Œæµ‹è¯•å¤±è´¥: {tool_name}")
                if execution_result["stderr"]:
                    logging.error(f"é”™è¯¯è¾“å‡º: {execution_result['stderr']}")
            
            return execution_result["success"], execution_result
            
        except subprocess.TimeoutExpired:
            execution_result["stderr"] = "æ‰§è¡Œè¶…æ—¶"
            logging.error(f"å·¥å…·æ‰§è¡Œè¶…æ—¶: {tool_name}")
            return False, execution_result
        except Exception as e:
            execution_result["stderr"] = str(e)
            logging.error(f"å·¥å…·æ‰§è¡Œå¼‚å¸¸ {tool_name}: {e}")
            return False, execution_result
    
    def test_single_tool(self, tool_name: str, full_run: bool = False) -> Dict[str, Any]:
        """æµ‹è¯•å•ä¸ªå·¥å…·"""
        logging.info(f"å¼€å§‹æµ‹è¯•å·¥å…·: {self.tools[tool_name]['description']}")
        
        test_result = {
            "tool_name": tool_name,
            "description": self.tools[tool_name]['description'],
            "tests": {
                "file_exists": False,
                "syntax_check": False,
                "dry_run": False,
                "full_execution": False
            },
            "execution_details": {},
            "overall_success": False
        }
        
        # æµ‹è¯•1: æ–‡ä»¶å­˜åœ¨æ€§
        test_result["tests"]["file_exists"] = self.test_tool_exists(tool_name)
        if not test_result["tests"]["file_exists"]:
            return test_result
            
        # æµ‹è¯•2: è¯­æ³•æ£€æŸ¥
        test_result["tests"]["syntax_check"] = self.test_tool_syntax(tool_name)
        if not test_result["tests"]["syntax_check"]:
            return test_result
            
        # æµ‹è¯•3: å¹²è·‘æµ‹è¯•
        dry_run_success, dry_run_details = self.test_tool_execution(tool_name, dry_run=True)
        test_result["tests"]["dry_run"] = dry_run_success
        test_result["execution_details"]["dry_run"] = dry_run_details
        
        # æµ‹è¯•4: å®Œæ•´æ‰§è¡Œï¼ˆå¯é€‰ï¼‰
        if full_run and dry_run_success:
            full_run_success, full_run_details = self.test_tool_execution(tool_name, dry_run=False)
            test_result["tests"]["full_execution"] = full_run_success
            test_result["execution_details"]["full_execution"] = full_run_details
        else:
            test_result["tests"]["full_execution"] = True  # è·³è¿‡æ—¶æ ‡è®°ä¸ºé€šè¿‡
            
        # è®¡ç®—æ€»ä½“æˆåŠŸç‡
        passed_tests = sum(test_result["tests"].values())
        total_tests = len(test_result["tests"])
        test_result["overall_success"] = (passed_tests == total_tests)
        
        logging.info(f"å·¥å…·æµ‹è¯•å®Œæˆ: {tool_name} - {'é€šè¿‡' if test_result['overall_success'] else 'å¤±è´¥'} ({passed_tests}/{total_tests})")
        
        return test_result
    
    def test_all_tools(self, full_run: bool = False) -> bool:
        """æµ‹è¯•æ‰€æœ‰å·¥å…·"""
        logging.info("å¼€å§‹æµ‹è¯•æ‰€æœ‰è¿ç§»å·¥å…·...")
        
        start_time = time.time()
        all_success = True
        
        for tool_name in self.tools.keys():
            try:
                test_result = self.test_single_tool(tool_name, full_run)
                self.test_report["test_results"][tool_name] = test_result
                self.test_report["tools_tested"].append(tool_name)
                
                if not test_result["overall_success"]:
                    all_success = False
                    
            except Exception as e:
                logging.error(f"æµ‹è¯•å·¥å…·æ—¶å‘ç”Ÿå¼‚å¸¸ {tool_name}: {e}")
                self.test_report["test_results"][tool_name] = {
                    "tool_name": tool_name,
                    "error": str(e),
                    "overall_success": False
                }
                all_success = False
        
        self.test_report["execution_time"] = time.time() - start_time
        self.test_report["overall_status"] = "PASS" if all_success else "FAIL"
        
        logging.info(f"æ‰€æœ‰å·¥å…·æµ‹è¯•å®Œæˆ - æ€»ä½“çŠ¶æ€: {self.test_report['overall_status']} (è€—æ—¶: {self.test_report['execution_time']:.2f}s)")
        
        return all_success
    
    def generate_test_summary(self):
        """ç”Ÿæˆæµ‹è¯•æ‘˜è¦"""
        print("\n" + "="*60)
        print("è¿ç§»å·¥å…·æµ‹è¯•æ‘˜è¦æŠ¥å‘Š")
        print("="*60)
        
        print(f"æµ‹è¯•æ—¶é—´: {self.test_report['timestamp']}")
        print(f"æ€»ä½“çŠ¶æ€: {self.test_report['overall_status']}")
        print(f"æ‰§è¡Œæ—¶é—´: {self.test_report['execution_time']:.2f}ç§’")
        print(f"æµ‹è¯•å·¥å…·æ•°: {len(self.test_report['tools_tested'])}")
        
        print(f"\nğŸ“‹ å·¥å…·æµ‹è¯•è¯¦æƒ…:")
        for tool_name, result in self.test_report["test_results"].items():
            if "error" in result:
                print(f"   âŒ {result.get('description', tool_name)}: æµ‹è¯•å¼‚å¸¸ - {result['error']}")
            else:
                status = "âœ…" if result["overall_success"] else "âŒ"
                tests = result["tests"]
                passed = sum(tests.values())
                total = len(tests)
                print(f"   {status} {result['description']}: {passed}/{total} æµ‹è¯•é€šè¿‡")
                
                # æ˜¾ç¤ºå…·ä½“æµ‹è¯•é¡¹
                for test_name, test_passed in tests.items():
                    test_status = "âœ“" if test_passed else "âœ—"
                    print(f"      {test_status} {test_name}")
        
        # æ˜¾ç¤ºå»ºè®®
        print(f"\nğŸ’¡ å»ºè®®:")
        failed_tools = [name for name, result in self.test_report["test_results"].items() 
                       if not result.get("overall_success", False)]
        
        if not failed_tools:
            print("   æ‰€æœ‰å·¥å…·æµ‹è¯•é€šè¿‡ï¼Œå¯ä»¥æ­£å¼ä½¿ç”¨ï¼")
        else:
            print(f"   éœ€è¦ä¿®å¤ä»¥ä¸‹å·¥å…·çš„é—®é¢˜: {', '.join(failed_tools)}")
            print("   è¯·æŸ¥çœ‹è¯¦ç»†æ—¥å¿—äº†è§£å…·ä½“é—®é¢˜ã€‚")
    
    def save_test_report(self):
        """ä¿å­˜æµ‹è¯•æŠ¥å‘Š"""
        report_file = self.project_root / "migration-tools-test-report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(self.test_report, f, ensure_ascii=False, indent=2)
        logging.info(f"æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

def main():
    """ä¸»å‡½æ•°"""
    # é¡¹ç›®æ ¹ç›®å½•
    project_root = r"D:\keycloak_sb_sso_new0910_claude\ps\ps-be"
    
    print("=" * 60)
    print("è¿ç§»å·¥å…·æµ‹è¯•è„šæœ¬ v1.0")
    print("åŠŸèƒ½: æµ‹è¯•è¿ç§»å·¥å…·ï¼ŒéªŒè¯åŠŸèƒ½æ­£ç¡®æ€§")
    print("=" * 60)
    
    # åˆ›å»ºæµ‹è¯•å™¨å®ä¾‹
    tester = MigrationToolTester(project_root)
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    full_run = "--full" in sys.argv
    if full_run:
        print("âš ï¸ å®Œæ•´è¿è¡Œæ¨¡å¼ï¼šå°†å®é™…æ‰§è¡Œæ‰€æœ‰å·¥å…·")
        user_input = input("æ˜¯å¦ç»§ç»­ï¼Ÿ(y/N): ").lower()
        if user_input != 'y':
            print("æµ‹è¯•å–æ¶ˆã€‚")
            return
    else:
        print("ğŸ§ª å®‰å…¨æµ‹è¯•æ¨¡å¼ï¼šä»…éªŒè¯å·¥å…·åŸºæœ¬åŠŸèƒ½")
    
    try:
        # è®¾ç½®æµ‹è¯•ç¯å¢ƒ
        if not tester.setup_test_environment():
            print("âŒ æµ‹è¯•ç¯å¢ƒè®¾ç½®å¤±è´¥")
            return
            
        # æ‰§è¡Œæµ‹è¯•
        success = tester.test_all_tools(full_run=full_run)
        
        # ç”ŸæˆæŠ¥å‘Š
        tester.generate_test_summary()
        tester.save_test_report()
        
        if success:
            print(f"\nğŸ‰ æ‰€æœ‰å·¥å…·æµ‹è¯•é€šè¿‡ï¼")
        else:
            print(f"\nâš ï¸ éƒ¨åˆ†å·¥å…·æµ‹è¯•å¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—ä¿®å¤é—®é¢˜ã€‚")
            
    except Exception as e:
        logging.error(f"æµ‹è¯•è¿‡ç¨‹å‡ºç°é”™è¯¯: {e}")
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        
    print(f"\næµ‹è¯•å®Œæˆï¼Œè¯¦ç»†ä¿¡æ¯è¯·æŸ¥çœ‹ tool-test.log å’Œ migration-tools-test-report.json")

if __name__ == "__main__":
    main()